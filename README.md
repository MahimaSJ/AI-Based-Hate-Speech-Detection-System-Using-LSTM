 The proliferation of social media has significantly amplified
 the spread of hate speech, creating a toxic digital environment.
 Manual monitoring methods are no longer sufficient due to
 the scale and velocity of content generation. The increasing
 demand for automated tools that detect and moderate such
 harmful content has led to the exploration of advanced NLP
based models. This paper introduces a Deep Learning model
 based on LSTM that can effectively detect hate speech in real
 time. We also present a web interface for easy user access and
 operational deployment.
 Hate speech, offensive content, and toxic behavior can lead
 to psychological harm, misinformation, and social unrest. By
 enabling automated detection systems, this project addresses
 a vital societal need and also contributes to the field of ethical
 AI.
 The importance of such systems is also reinforced by gov
ernmental and institutional calls for improved online content
 regulation. This project aligns with broader efforts to ensure
 internet safety through AI-powered solutions.
